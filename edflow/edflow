#!/usr/bin/env python3

import os

pytorch_mp = os.environ.get('USE_PYTORCH_MP', 'False') == 'True'
if not pytorch_mp:
    import multiprocessing as mp
    # mp = _mp.set_start_method('spawn')
else:
    print('Using pytorch mp')
    import torch.multiprocessing as mp

import sys  # noqa
import argparse  # noqa
import yaml  # noqa

# import tensorflow as tf
from edflow.main import train, test  # noqa
from edflow.custom_logging import init_project, use_project, get_logger  # noqa

sys.path.append(os.getcwd())  # convenience: load implementations from cwd

def update_config(config, options):
    if options is not None:
        for option in options:
            config.update(yaml.load(option))

def main(opt):
    # Project manager
    if opt.project is not None:
        P = use_project(opt.project, postfix = opt.name)
    else:
        assert opt.train is not None
        # get path to implementation
        with open(opt.train) as f:
            config = yaml.load(f)
            update_config(config, opt.option)
            impl = config["model"]
            name = config.get("experiment_name", None)
        # if it looks like a package path, take its root as the code dir
        # otherwise take cwd
        path = impl.split(".")
        if len(path) > 0:
            code_root = path[0]
        else:
            code_root = "."
        if opt.name is not None:
            # command line takes precedence over "experiment_name" from
            # config
            name = opt.name
        P = init_project('logs', code_root=code_root, postfix=name)

    # Logger
    logger = get_logger('main')
    logger.info(opt)
    logger.info(P)

    # Processes
    processes = list()

    # Error Communication between processes
    JQ = mp.Queue()

    # Training
    if opt.train:
        if opt.checkpoint is not None:
            checkpoint = opt.checkpoint
        elif opt.project is not None:
            # TODO remove tf dependency here
            checkpoint = tf.train.latest_checkpoint(P.checkpoints)
        else:
            checkpoint = None
        with open(opt.train) as f:
            config = yaml.load(f)
            update_config(config, opt.option)

        logger.info("Training config: {}".format(opt.train))
        logger.info(yaml.dump(config))

        train_process = mp.Process(target=train,
                                   args=((config,
                                         P.train,
                                         checkpoint,
                                         opt.retrain),
                                         JQ, len(processes)))
        processes.append(train_process)

    # Evaluation
    opt.eval = opt.eval or list()
    for eval_idx, eval_config in enumerate(opt.eval):
        with open(eval_config) as f:
            config = yaml.load(f)
            update_config(config, opt.option)
        logger.info("Evaluation config: {}".format(eval_config))
        logger.info(yaml.dump(config))
        nogpu = len(processes) > 0 or opt.nogpu
        bar_position = len(processes) + eval_idx
        test_process = mp.Process(target=test,
                                  args=((config, P.latest_eval,
                                         nogpu, bar_position),
                                        JQ, len(processes)))
        processes.append(test_process)

    # Take off
    try:
        for p in processes:
            p.start()
        logger.info("Started {} process(es).".format(len(processes)))

        done_count = 0
        while True:
            pidx, exc_or_done, trace = JQ.get()
            if isinstance(exc_or_done, Exception):
                logger.warn("Exception in process {}:".format(pidx))
                logger.warn(trace)
                raise exc_or_done
            elif exc_or_done == 'Done':
                logger.info('Process {} is done'.format(pidx))
                done_count += 1
            else:
                raise Exception("Unknown element on queue.")

            if done_count >= len(processes):
                break

    # Landing
        for p in processes:
            p.join()

    except Exception:
        logger.info('Terminating all processes')
        for p in processes:
            p.terminate()
    finally:
        logger.info('Finished')



if __name__ == "__main__":
    default_log_dir = os.path.join(os.getcwd(), "log")

    parser = argparse.ArgumentParser()
    parser.add_argument("-n", "--name",
            metavar = "description", help="postfix of log directory.")
    parser.add_argument("-t", "--train",
            metavar = "config.yaml", help="path to training config")
    parser.add_argument("-e", "--eval", nargs = "*",
            metavar = "config.yaml", help="path to evaluation configs")
    parser.add_argument("-p", "--project", help="path to existing project")
    parser.add_argument("-c", "--checkpoint", help="path to existing checkpoint")
    parser.add_argument("-r", "--retrain", action = "store_true", help="reset global step")
    parser.add_argument("--nogpu", action = "store_true", help="disable gpu for tensorflow")
    parser.add_argument("--option", "-o", action = "append",
            help="additional key: value options to update all config with")
    opt = parser.parse_args()
    main(opt)
